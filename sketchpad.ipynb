{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "model_name = \"HuggingFaceTB/SmolLM2-135M\"\n",
    "dataset_path = \"HuggingFaceTB/smoltalk\"\n",
    "dataset_name = \"everyday-conversations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([49152, 576])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embeddying layer\n",
    "\n",
    "embedding_layer = model.model.embed_tokens\n",
    "embedding_layer.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "torch.Size([2, 3])\n",
      "tensor([[4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "test = torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(test)\n",
    "print(test.shape)\n",
    "print(test[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.1768e-01,  2.7832e-02,  4.8096e-02, -7.9346e-03, -5.6152e-02,\n",
       "        -5.2002e-02,  1.6479e-02, -1.3379e-01,  1.0791e-01, -2.2949e-01,\n",
       "         3.1982e-02, -4.6631e-02,  2.2852e-01, -3.3398e-01, -3.1836e-01,\n",
       "         2.7832e-02, -1.3611e-02,  6.3965e-02, -1.2109e-01, -5.1758e-02,\n",
       "         3.1250e-02,  2.2461e-01, -6.6406e-02,  8.2031e-02, -8.3008e-03,\n",
       "        -1.0620e-02, -6.7871e-02,  5.3223e-02,  1.6406e-01,  1.3672e-01,\n",
       "         7.2266e-02, -2.0020e-01, -1.0059e-01, -1.5137e-01,  2.2095e-02,\n",
       "        -3.1128e-03,  4.5410e-02,  8.3008e-02,  6.3477e-02, -1.0205e-01,\n",
       "         8.4473e-02,  1.4160e-01,  3.2471e-02,  2.4048e-02,  9.5703e-02,\n",
       "        -5.8594e-02,  1.4746e-01, -1.9629e-01,  3.8086e-02, -1.4844e-01,\n",
       "         1.8652e-01, -1.1719e-01,  9.9609e-02, -1.3184e-01,  2.5513e-02,\n",
       "         1.1133e-01,  4.0527e-02,  1.8164e-01, -7.0312e-02,  1.6724e-02,\n",
       "         9.7046e-03,  2.1515e-03,  1.2891e-01, -1.0010e-02, -8.9844e-02,\n",
       "        -1.1572e-01,  1.0254e-01, -1.8158e-03, -1.5137e-01,  2.4316e-01,\n",
       "         7.8125e-03, -1.3281e-01,  6.3965e-02, -9.2285e-02,  8.4961e-02,\n",
       "        -3.2959e-02, -3.1250e-01,  1.0010e-01,  9.7656e-03,  4.7302e-03,\n",
       "         1.0791e-01,  1.7578e-02,  5.3467e-02,  5.3223e-02,  1.5527e-01,\n",
       "         2.2705e-02,  1.2573e-02, -5.3955e-02, -3.6865e-02, -1.5039e-01,\n",
       "         1.9531e-02,  3.0060e-03,  4.1748e-02,  5.3711e-02,  4.7852e-02,\n",
       "         3.0151e-02, -8.5938e-02,  8.3618e-03, -2.3926e-01, -2.9102e-01,\n",
       "         4.8096e-02, -1.4258e-01, -1.2779e-04,  1.4648e-02,  1.3855e-02,\n",
       "         2.6611e-02,  2.9175e-02,  1.0498e-01,  1.8066e-01,  6.3477e-02,\n",
       "        -5.7373e-02,  2.4292e-02, -2.8442e-02,  7.4707e-02, -8.2520e-02,\n",
       "         3.3203e-02, -5.2734e-02, -1.2988e-01,  8.5449e-02,  5.0293e-02,\n",
       "        -1.0938e-01, -1.5039e-01, -2.0117e-01,  1.6479e-02, -1.5430e-01,\n",
       "         9.5215e-02,  2.0020e-02, -1.8359e-01,  3.5400e-02, -9.0820e-02,\n",
       "         6.0059e-02, -7.5684e-02, -2.5513e-02, -4.4189e-02,  6.8848e-02,\n",
       "         1.1865e-01, -6.2988e-02, -1.0156e-01,  2.3340e-01, -8.0078e-02,\n",
       "         1.9629e-01, -1.7212e-02,  8.1055e-02, -1.1475e-02,  1.5332e-01,\n",
       "         5.3711e-02, -1.3281e-01,  3.3203e-02, -1.1719e-02, -3.1250e-02,\n",
       "         5.0354e-03,  6.9824e-02, -1.0547e-01, -1.4355e-01, -9.9121e-02,\n",
       "         6.4941e-02,  3.8330e-02,  1.1035e-01, -1.2500e-01,  1.5527e-01,\n",
       "        -2.5269e-02,  1.6797e-01, -1.1670e-01, -9.5215e-02, -1.9043e-02,\n",
       "         7.8613e-02, -7.9102e-02,  7.4158e-03,  9.7168e-02, -8.0078e-02,\n",
       "        -1.2988e-01,  2.6172e-01,  1.6699e-01,  1.4062e-01,  1.9238e-01,\n",
       "        -3.4375e-01, -4.5166e-03,  2.5635e-02, -1.8457e-01,  5.7129e-02,\n",
       "         7.9956e-03,  1.3281e-01,  4.0527e-02,  1.6992e-01, -3.3936e-02,\n",
       "        -3.1494e-02,  1.9824e-01,  2.4780e-02, -1.8262e-01,  1.5527e-01,\n",
       "        -1.7334e-02, -7.6172e-02, -8.2520e-02, -1.9043e-02, -3.6621e-02,\n",
       "         5.9082e-02, -2.6733e-02,  1.6992e-01,  9.7656e-02,  3.6719e-01,\n",
       "         1.4893e-02, -2.3438e-01, -1.8164e-01,  1.1572e-01,  5.9082e-02,\n",
       "        -3.0078e-01,  5.9326e-02, -1.4648e-01,  5.0537e-02, -6.3965e-02,\n",
       "        -1.1523e-01, -5.4199e-02,  4.8828e-02,  6.0791e-02, -1.4355e-01,\n",
       "         1.1328e-01, -3.3398e-01, -1.0010e-02,  5.7373e-02,  7.0801e-02,\n",
       "         4.2236e-02,  1.0693e-01, -1.7090e-01,  9.4727e-02, -1.1719e-01,\n",
       "         6.2256e-02,  3.1494e-02, -1.5820e-01,  5.8350e-02, -1.1230e-01,\n",
       "        -4.9744e-03,  3.0273e-02, -5.4443e-02,  1.1475e-01,  1.3916e-02,\n",
       "        -1.4551e-01, -1.7969e-01, -3.4180e-01, -8.5938e-02, -1.2256e-01,\n",
       "         6.6895e-02, -1.2756e-02,  1.7090e-01, -2.1240e-02,  7.8613e-02,\n",
       "         1.0156e-01,  3.9795e-02,  3.3789e-01,  1.1572e-01, -3.7354e-02,\n",
       "         2.1387e-01,  1.5723e-01, -7.8613e-02,  1.4453e-01,  2.6758e-01,\n",
       "        -1.5430e-01,  1.5442e-02, -1.3770e-01, -4.0283e-02, -4.6875e-02,\n",
       "        -5.0391e-01,  1.9531e-01, -2.5781e-01,  5.1514e-02,  2.2430e-03,\n",
       "         1.8848e-01, -9.0820e-02,  3.2806e-03,  1.3770e-01,  1.2085e-02,\n",
       "        -1.0376e-02, -1.8066e-01,  3.1494e-02,  9.1797e-02, -1.3184e-01,\n",
       "        -6.0547e-02, -2.7832e-02, -9.7656e-02,  5.2246e-02,  8.0078e-02,\n",
       "         8.2031e-02,  2.0020e-02, -6.5002e-03, -1.2695e-01, -3.9795e-02,\n",
       "        -4.5654e-02,  8.3008e-02,  5.1514e-02, -8.3984e-02, -1.3281e-01,\n",
       "        -2.4536e-02, -1.9141e-01,  1.3965e-01, -9.2285e-02,  9.7168e-02,\n",
       "        -3.1738e-02, -6.5430e-02, -1.5234e-01, -1.4551e-01,  3.9307e-02,\n",
       "         1.5869e-02, -1.2695e-01,  1.6211e-01, -3.1836e-01, -1.5332e-01,\n",
       "        -1.4941e-01, -2.9102e-01,  9.0820e-02,  1.7090e-03,  6.6406e-02,\n",
       "        -2.6953e-01,  5.5908e-02,  1.0156e-01, -1.3867e-01,  1.9531e-01,\n",
       "        -6.2256e-03,  4.7607e-02, -9.6680e-02,  1.2207e-01, -5.0537e-02,\n",
       "        -3.1738e-02,  1.4282e-02, -9.6191e-02, -9.9609e-02,  5.7678e-03,\n",
       "        -8.8867e-02, -7.7637e-02, -7.8125e-02,  9.2285e-02, -4.1016e-02,\n",
       "        -1.1377e-01, -7.0312e-02,  2.2363e-01, -8.6426e-02, -1.5137e-02,\n",
       "         2.1484e-01,  5.9814e-02, -1.2891e-01, -2.4048e-02, -1.0059e-01,\n",
       "        -2.0410e-01,  2.1582e-01,  5.0293e-02,  1.5869e-02,  5.8594e-02,\n",
       "         1.0254e-02, -8.7891e-02, -1.2012e-01,  1.7578e-01, -6.3477e-02,\n",
       "         9.7656e-02,  1.8921e-02, -6.8359e-02, -3.4180e-02, -1.6479e-02,\n",
       "         9.4238e-02, -3.1641e-01,  5.8594e-02, -9.0820e-02, -2.5391e-01,\n",
       "         2.3730e-01, -2.4316e-01, -3.2471e-02,  1.0303e-01,  1.0352e-01,\n",
       "        -1.4648e-01, -1.1768e-01,  4.4434e-02,  1.2451e-01,  3.6377e-02,\n",
       "        -6.8359e-03,  1.7871e-01,  1.4282e-02,  1.2207e-01,  1.1816e-01,\n",
       "        -9.8267e-03, -5.4932e-02, -1.1047e-02,  1.9531e-01,  1.2891e-01,\n",
       "         5.8365e-04,  1.8457e-01, -8.2031e-02, -7.8125e-02,  6.3477e-02,\n",
       "        -1.4526e-02,  1.5918e-01, -1.1328e-01,  9.9121e-02, -7.6660e-02,\n",
       "        -8.4305e-04, -7.6172e-02,  2.1729e-02,  1.1621e-01,  2.2217e-02,\n",
       "        -1.4160e-01,  1.8848e-01,  1.7188e-01,  2.4121e-01,  1.4465e-02,\n",
       "        -1.7969e-01,  4.3945e-02,  2.8809e-02,  2.1777e-01, -8.3008e-02,\n",
       "         1.0449e-01, -2.3438e-02,  2.6953e-01,  3.7305e-01, -7.4219e-02,\n",
       "         1.2500e-01,  1.7676e-01, -1.7090e-01, -1.8652e-01, -1.0315e-02,\n",
       "        -1.3965e-01,  2.5781e-01, -6.6895e-02, -1.4877e-03, -9.9609e-02,\n",
       "         7.9102e-02, -1.1865e-01,  2.9175e-02, -1.3855e-02, -4.4189e-02,\n",
       "        -3.0078e-01, -1.7929e-03,  5.7861e-02, -9.8633e-02, -1.8921e-02,\n",
       "        -1.8262e-01,  1.1963e-01, -1.0107e-01,  3.0664e-01, -1.1426e-01,\n",
       "         4.3457e-02, -8.7891e-03, -1.2793e-01, -8.3496e-02,  5.2979e-02,\n",
       "        -5.4199e-02,  7.4219e-02, -8.3496e-02, -3.9062e-02, -4.1809e-03,\n",
       "        -3.3691e-02, -9.6680e-02, -2.8931e-02,  4.4434e-02,  1.6113e-02,\n",
       "        -6.6895e-02, -2.6367e-01, -8.4473e-02, -6.2988e-02, -3.9551e-02,\n",
       "        -8.9355e-02, -8.3008e-02,  1.5869e-02,  1.2793e-01, -1.6602e-01,\n",
       "         5.2979e-02, -1.0010e-01, -1.6797e-01,  2.9785e-02, -2.9102e-01,\n",
       "        -1.8921e-02,  8.3496e-02,  1.8652e-01, -5.0781e-02,  2.0020e-01,\n",
       "        -2.1875e-01, -1.2695e-01, -3.9795e-02,  2.1094e-01, -2.2705e-02,\n",
       "        -9.1309e-02, -1.0352e-01,  1.9043e-01,  9.3750e-02, -3.3203e-01,\n",
       "        -8.3008e-02,  1.5234e-01,  1.0205e-01, -1.2012e-01,  1.5332e-01,\n",
       "         1.4954e-02, -2.1729e-02,  1.1035e-01, -2.8809e-02,  1.4160e-01,\n",
       "         1.0352e-01,  7.7209e-03,  3.4912e-02, -1.8066e-02,  2.1289e-01,\n",
       "         1.4746e-01,  1.2207e-01,  7.7148e-02, -5.5908e-02,  1.1084e-01,\n",
       "         2.0508e-01,  8.9355e-02, -5.4016e-03,  1.1084e-01, -1.9531e-02,\n",
       "        -1.0596e-01, -5.6885e-02,  2.3633e-01,  8.9355e-02,  2.4170e-02,\n",
       "        -3.2471e-02, -1.5137e-01, -6.3477e-02,  5.5908e-02,  3.8330e-02,\n",
       "         1.2695e-01, -8.8379e-02, -2.0386e-02,  2.5024e-02, -2.3193e-02,\n",
       "         5.0781e-02,  1.0840e-01,  2.3340e-01,  7.5684e-02, -5.0293e-02,\n",
       "        -6.3477e-02,  2.9541e-02, -1.0889e-01,  1.2158e-01,  6.5430e-02,\n",
       "        -4.6143e-02,  1.8164e-01,  1.3123e-02, -2.7148e-01,  1.6602e-01,\n",
       "         8.6426e-02,  1.1865e-01, -5.0049e-02, -4.6387e-02, -1.1328e-01,\n",
       "        -1.3184e-01, -2.5000e-01, -2.7539e-01, -1.2402e-01, -3.1006e-02,\n",
       "         9.0332e-03,  3.2959e-02, -1.2158e-01, -1.7212e-02,  1.0840e-01,\n",
       "        -1.8066e-01,  4.5410e-02,  6.8054e-03, -1.0620e-02,  1.5076e-02,\n",
       "         1.0254e-01, -4.3701e-02, -1.5332e-01, -1.0889e-01,  8.6914e-02,\n",
       "         5.6641e-02,  2.6978e-02,  1.2500e-01, -9.7046e-03,  1.2891e-01,\n",
       "         2.3340e-01, -1.0547e-01,  2.0605e-01,  1.2512e-03,  5.1758e-02,\n",
       "        -1.2891e-01, -1.1816e-01,  8.5449e-03, -2.2827e-02, -2.5195e-01,\n",
       "         2.8320e-02], device='mps:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer.weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "The operator 'aten::_linalg_eigvals' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize_token_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.12/site-packages/transformers/modeling_utils.py:2058\u001b[0m, in \u001b[0;36mPreTrainedModel.resize_token_embeddings\u001b[0;34m(self, new_num_tokens, pad_to_multiple_of, mean_resizing)\u001b[0m\n\u001b[1;32m   2022\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mresize_token_embeddings\u001b[39m(\n\u001b[1;32m   2023\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2024\u001b[0m     new_num_tokens: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2025\u001b[0m     pad_to_multiple_of: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2026\u001b[0m     mean_resizing: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   2027\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m nn\u001b[38;5;241m.\u001b[39mEmbedding:\n\u001b[1;32m   2028\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2029\u001b[0m \u001b[38;5;124;03m    Resizes input token embeddings matrix of the model if `new_num_tokens != config.vocab_size`.\u001b[39;00m\n\u001b[1;32m   2030\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2056\u001b[0m \u001b[38;5;124;03m        `torch.nn.Embedding`: Pointer to the input tokens Embeddings Module of the model.\u001b[39;00m\n\u001b[1;32m   2057\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2058\u001b[0m     model_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resize_token_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_num_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean_resizing\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2059\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m new_num_tokens \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m pad_to_multiple_of \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2060\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m model_embeds\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.12/site-packages/transformers/modeling_utils.py:2083\u001b[0m, in \u001b[0;36mPreTrainedModel._resize_token_embeddings\u001b[0;34m(self, new_num_tokens, pad_to_multiple_of, mean_resizing)\u001b[0m\n\u001b[1;32m   2081\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_resize_token_embeddings\u001b[39m(\u001b[38;5;28mself\u001b[39m, new_num_tokens, pad_to_multiple_of\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, mean_resizing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   2082\u001b[0m     old_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_input_embeddings()\n\u001b[0;32m-> 2083\u001b[0m     new_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_resized_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2084\u001b[0m \u001b[43m        \u001b[49m\u001b[43mold_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_num_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean_resizing\u001b[49m\n\u001b[1;32m   2085\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2086\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(old_embeddings, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_hf_hook\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   2087\u001b[0m         hook \u001b[38;5;241m=\u001b[39m old_embeddings\u001b[38;5;241m.\u001b[39m_hf_hook\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.12/site-packages/transformers/modeling_utils.py:2237\u001b[0m, in \u001b[0;36mPreTrainedModel._get_resized_embeddings\u001b[0;34m(self, old_embeddings, new_num_tokens, pad_to_multiple_of, mean_resizing)\u001b[0m\n\u001b[1;32m   2233\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_added_embeddings_weights_with_mean(\n\u001b[1;32m   2234\u001b[0m                 old_embeddings, new_embeddings, old_embedding_dim, old_num_tokens, added_num_tokens\n\u001b[1;32m   2235\u001b[0m             )\n\u001b[1;32m   2236\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2237\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_added_embeddings_weights_with_mean\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2238\u001b[0m \u001b[43m            \u001b[49m\u001b[43mold_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mold_embedding_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mold_num_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madded_num_tokens\u001b[49m\n\u001b[1;32m   2239\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2241\u001b[0m \u001b[38;5;66;03m# Copy token embeddings from the previous weights\u001b[39;00m\n\u001b[1;32m   2242\u001b[0m \n\u001b[1;32m   2243\u001b[0m \u001b[38;5;66;03m# numbers of tokens to copy\u001b[39;00m\n\u001b[1;32m   2244\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(old_num_tokens, new_num_tokens)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.12/site-packages/transformers/modeling_utils.py:2415\u001b[0m, in \u001b[0;36mPreTrainedModel._init_added_embeddings_weights_with_mean\u001b[0;34m(self, old_embeddings, new_embeddings, old_embedding_dim, old_num_tokens, added_num_tokens)\u001b[0m\n\u001b[1;32m   2412\u001b[0m covariance \u001b[38;5;241m=\u001b[39m old_centered_embeddings\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m old_centered_embeddings \u001b[38;5;241m/\u001b[39m old_num_tokens\n\u001b[1;32m   2414\u001b[0m \u001b[38;5;66;03m# Check if the covariance is positive definite.\u001b[39;00m\n\u001b[0;32m-> 2415\u001b[0m eigenvalues \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meigvals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcovariance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2416\u001b[0m is_covariance_psd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(\n\u001b[1;32m   2417\u001b[0m     (covariance \u001b[38;5;241m==\u001b[39m covariance\u001b[38;5;241m.\u001b[39mT)\u001b[38;5;241m.\u001b[39mall() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_complex(eigenvalues) \u001b[38;5;129;01mand\u001b[39;00m (eigenvalues \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mall()\n\u001b[1;32m   2418\u001b[0m )\n\u001b[1;32m   2419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_covariance_psd:\n\u001b[1;32m   2420\u001b[0m     \u001b[38;5;66;03m# If covariances is positive definite, a distribution can be created. and we can sample new weights from it.\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: The operator 'aten::_linalg_eigvals' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS."
     ]
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tokenizer)+8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Tokenizer and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<|endoftext|>',\n",
       " 'eos_token': '<|endoftext|>',\n",
       " 'unk_token': '<|endoftext|>',\n",
       " 'additional_special_tokens': ['<|endoftext|>',\n",
       "  '<|im_start|>',\n",
       "  '<|im_end|>',\n",
       "  '<repo_name>',\n",
       "  '<reponame>',\n",
       "  '<file_sep>',\n",
       "  '<filename>',\n",
       "  '<gh_stars>',\n",
       "  '<issue_start>',\n",
       "  '<issue_comment>',\n",
       "  '<issue_closed>',\n",
       "  '<jupyter_start>',\n",
       "  '<jupyter_text>',\n",
       "  '<jupyter_code>',\n",
       "  '<jupyter_output>',\n",
       "  '<jupyter_script>',\n",
       "  '<empty_output>']}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['full_topic', 'messages'],\n",
       "        num_rows: 2260\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['full_topic', 'messages'],\n",
       "        num_rows: 119\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(dataset_path, dataset_name)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'Hi there', 'role': 'user'},\n",
       " {'content': 'Hello! How can I help you today?', 'role': 'assistant'},\n",
       " {'content': \"I'm looking for a beach resort for my next vacation. Can you recommend some popular ones?\",\n",
       "  'role': 'user'},\n",
       " {'content': \"Some popular beach resorts include Maui in Hawaii, the Maldives, and the Bahamas. They're known for their beautiful beaches and crystal-clear waters.\",\n",
       "  'role': 'assistant'},\n",
       " {'content': 'That sounds great. Are there any resorts in the Caribbean that are good for families?',\n",
       "  'role': 'user'},\n",
       " {'content': 'Yes, the Turks and Caicos Islands and Barbados are excellent choices for family-friendly resorts in the Caribbean. They offer a range of activities and amenities suitable for all ages.',\n",
       "  'role': 'assistant'},\n",
       " {'content': \"Okay, I'll look into those. Thanks for the recommendations!\",\n",
       "  'role': 'user'},\n",
       " {'content': \"You're welcome. I hope you find the perfect resort for your vacation.\",\n",
       "  'role': 'assistant'}]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0][\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'full_topic': Value(dtype='string', id=None),\n",
       " 'messages': [{'content': Value(dtype='string', id=None),\n",
       "   'role': Value(dtype='string', id=None)}]}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'full_topic': 'Travel/Vacation destinations/Beach resorts',\n",
       " 'messages': [{'content': 'Hi there', 'role': 'user'},\n",
       "  {'content': 'Hello! How can I help you today?', 'role': 'assistant'},\n",
       "  {'content': \"I'm looking for a beach resort for my next vacation. Can you recommend some popular ones?\",\n",
       "   'role': 'user'},\n",
       "  {'content': \"Some popular beach resorts include Maui in Hawaii, the Maldives, and the Bahamas. They're known for their beautiful beaches and crystal-clear waters.\",\n",
       "   'role': 'assistant'},\n",
       "  {'content': 'That sounds great. Are there any resorts in the Caribbean that are good for families?',\n",
       "   'role': 'user'},\n",
       "  {'content': 'Yes, the Turks and Caicos Islands and Barbados are excellent choices for family-friendly resorts in the Caribbean. They offer a range of activities and amenities suitable for all ages.',\n",
       "   'role': 'assistant'},\n",
       "  {'content': \"Okay, I'll look into those. Thanks for the recommendations!\",\n",
       "   'role': 'user'},\n",
       "  {'content': \"You're welcome. I hope you find the perfect resort for your vacation.\",\n",
       "   'role': 'assistant'}]}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49152"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": ectable\n",
      ": \n",
      ": \n"
     ]
    }
   ],
   "source": [
    "print(\":\", tokenizer.decode(49151))\n",
    "print(\":\", tokenizer.decode(49152))\n",
    "print(\":\", tokenizer.decode(49153))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [44, 108, 16384, 108, 46], 'attention_mask': [1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"<|pad|>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<|endoftext|>',\n",
       " 'eos_token': '<|endoftext|>',\n",
       " 'unk_token': '<|endoftext|>',\n",
       " 'additional_special_tokens': ['<|endoftext|>',\n",
       "  '<|im_start|>',\n",
       "  '<|im_end|>',\n",
       "  '<repo_name>',\n",
       "  '<reponame>',\n",
       "  '<file_sep>',\n",
       "  '<filename>',\n",
       "  '<gh_stars>',\n",
       "  '<issue_start>',\n",
       "  '<issue_comment>',\n",
       "  '<issue_closed>',\n",
       "  '<jupyter_start>',\n",
       "  '<jupyter_text>',\n",
       "  '<jupyter_code>',\n",
       "  '<jupyter_output>',\n",
       "  '<jupyter_script>',\n",
       "  '<empty_output>']}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49152"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tokenizer.add_special_tokens({'pad_token': '<|pad|>'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49153"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49152"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<|endoftext|>',\n",
       " 'eos_token': '<|endoftext|>',\n",
       " 'unk_token': '<|endoftext|>',\n",
       " 'pad_token': '<|pad|>',\n",
       " 'additional_special_tokens': ['<|endoftext|>',\n",
       "  '<|im_start|>',\n",
       "  '<|im_end|>',\n",
       "  '<repo_name>',\n",
       "  '<reponame>',\n",
       "  '<file_sep>',\n",
       "  '<filename>',\n",
       "  '<gh_stars>',\n",
       "  '<issue_start>',\n",
       "  '<issue_comment>',\n",
       "  '<issue_closed>',\n",
       "  '<jupyter_start>',\n",
       "  '<jupyter_text>',\n",
       "  '<jupyter_code>',\n",
       "  '<jupyter_output>',\n",
       "  '<jupyter_script>',\n",
       "  '<empty_output>']}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      " world\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(tokens[\"input_ids\"][0]))\n",
    "print(tokenizer.decode(tokens[\"input_ids\"][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "Ġworld\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens(tokens[\"input_ids\"][0]))\n",
    "print(tokenizer.convert_ids_to_tokens(tokens[\"input_ids\"][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[28120, 905, 339, 5248, 294, 19712, 2715, 46119, 49152, 49152, 49152], [28120, 905, 339, 5248, 294, 19712, 2715, 46119, 16809, 10567, 3443]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer(\n",
    "    [\n",
    "        \"hello world I'm hugging face tokenizer\",\n",
    "        \"hello world I'm hugging face tokenizer padding paddding\",\n",
    "    ],\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    ")\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world I'm hugging face tokenizer<|pad|><|pad|><|pad|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(tokens[\"input_ids\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'Hi there', 'role': 'user'}, {'content': 'Hello! How can I help you today?', 'role': 'assistant'}, {'content': \"I'm looking for a beach resort for my next vacation. Can you recommend some popular ones?\", 'role': 'user'}, {'content': \"Some popular beach resorts include Maui in Hawaii, the Maldives, and the Bahamas. They're known for their beautiful beaches and crystal-clear waters.\", 'role': 'assistant'}, {'content': 'That sounds great. Are there any resorts in the Caribbean that are good for families?', 'role': 'user'}, {'content': 'Yes, the Turks and Caicos Islands and Barbados are excellent choices for family-friendly resorts in the Caribbean. They offer a range of activities and amenities suitable for all ages.', 'role': 'assistant'}, {'content': \"Okay, I'll look into those. Thanks for the recommendations!\", 'role': 'user'}, {'content': \"You're welcome. I hope you find the perfect resort for your vacation.\", 'role': 'assistant'}]\n"
     ]
    }
   ],
   "source": [
    "sample_data = dataset[\"train\"][0][\"messages\"]\n",
    "print(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": None\n"
     ]
    }
   ],
   "source": [
    "print(\":\", tokenizer.chat_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    }
   ],
   "source": [
    "from trl import setup_chat_format\n",
    "\n",
    "model, tokenizer = setup_chat_format(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{% for message in messages %}{{'<|im_start|>' + message['role'] + '\n",
      "' + message['content'] + '<|im_end|>' + '\n",
      "'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n",
      "' }}{% endif %}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.chat_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hello! How can I help you today?<|im_end|>\n",
      "<|im_start|>user\n",
      "I'm looking for a beach resort for my next vacation. Can you recommend some popular ones?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Some popular beach resorts include Maui in Hawaii, the Maldives, and the Bahamas. They're known for their beautiful beaches and crystal-clear waters.<|im_end|>\n",
      "<|im_start|>user\n",
      "That sounds great. Are there any resorts in the Caribbean that are good for families?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Yes, the Turks and Caicos Islands and Barbados are excellent choices for family-friendly resorts in the Caribbean. They offer a range of activities and amenities suitable for all ages.<|im_end|>\n",
      "<|im_start|>user\n",
      "Okay, I'll look into those. Thanks for the recommendations!<|im_end|>\n",
      "<|im_start|>assistant\n",
      "You're welcome. I hope you find the perfect resort for your vacation.<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.apply_chat_template(sample_data, tokenize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'full_topic': 'Travel/Vacation destinations/Beach resorts',\n",
       " 'messages': [{'content': 'Hi there', 'role': 'user'},\n",
       "  {'content': 'Hello! How can I help you today?', 'role': 'assistant'},\n",
       "  {'content': \"I'm looking for a beach resort for my next vacation. Can you recommend some popular ones?\",\n",
       "   'role': 'user'},\n",
       "  {'content': \"Some popular beach resorts include Maui in Hawaii, the Maldives, and the Bahamas. They're known for their beautiful beaches and crystal-clear waters.\",\n",
       "   'role': 'assistant'},\n",
       "  {'content': 'That sounds great. Are there any resorts in the Caribbean that are good for families?',\n",
       "   'role': 'user'},\n",
       "  {'content': 'Yes, the Turks and Caicos Islands and Barbados are excellent choices for family-friendly resorts in the Caribbean. They offer a range of activities and amenities suitable for all ages.',\n",
       "   'role': 'assistant'},\n",
       "  {'content': \"Okay, I'll look into those. Thanks for the recommendations!\",\n",
       "   'role': 'user'},\n",
       "  {'content': \"You're welcome. I hope you find the perfect resort for your vacation.\",\n",
       "   'role': 'assistant'}]}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c105e3ab7df404aafba0a50585ec102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/119 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To keep the data as a dataset, use the Dataset.map() method.\n",
    "# HF datasets are Apace Arrow files. It keeps data on the disk and only loads the samples in memory when needed.\n",
    "\n",
    "dataset = dataset.map(\n",
    "    lambda x: {\"input_ids\": tokenizer.apply_chat_template(x[\"messages\"])},\n",
    "    batched=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4093, 198, 26843, 665, 2, 198, 1, 520, 9531, 198, 19556, 17, 1073, 416, 339, 724, 346, 1834, 47, 2, 198, 1, 4093, 198, 57, 5248, 3012, 327, 253, 10724, 14500, 327, 957, 1867, 17584, 30, 1978, 346, 3730, 634, 2378, 2911, 47, 2, 198, 1, 520, 9531, 198, 4449, 2378, 10724, 36088, 1453, 48326, 281, 14126, 28, 260, 48148, 898, 28, 284, 260, 44057, 30, 1069, 2316, 1343, 327, 480, 3953, 16351, 284, 13253, 29, 10086, 5656, 30, 2, 198, 1, 4093, 198, 5195, 4598, 1109, 30, 4184, 665, 750, 36088, 281, 260, 11981, 338, 359, 1123, 327, 3168, 47, 2, 198, 1, 520, 9531, 198, 10539, 28, 260, 25518, 284, 7784, 48096, 10015, 284, 47557, 395, 359, 5412, 4975, 327, 1564, 29, 9263, 36088, 281, 260, 11981, 30, 1069, 2626, 253, 1845, 282, 2123, 284, 32255, 5712, 327, 511, 6399, 30, 2, 198, 1, 4093, 198, 39122, 28, 339, 3060, 1492, 618, 967, 30, 10090, 327, 260, 7400, 17, 2, 198, 1, 520, 9531, 198, 2683, 2316, 10668, 30, 339, 3826, 346, 1042, 260, 3468, 14500, 327, 469, 17584, 30, 2, 198]\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"train\"][0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user\n",
      "Hi there<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Hello! How can I help you today?<|im_end|>\n",
      "<|im_start|>user\n",
      "I'm looking for a beach resort for my next vacation. Can you recommend some popular ones?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Some popular beach resorts include Maui in Hawaii, the Maldives, and the Bahamas. They're known for their beautiful beaches and crystal-clear waters.<|im_end|>\n",
      "<|im_start|>user\n",
      "That sounds great. Are there any resorts in the Caribbean that are good for families?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Yes, the Turks and Caicos Islands and Barbados are excellent choices for family-friendly resorts in the Caribbean. They offer a range of activities and amenities suitable for all ages.<|im_end|>\n",
      "<|im_start|>user\n",
      "Okay, I'll look into those. Thanks for the recommendations!<|im_end|>\n",
      "<|im_start|>assistant\n",
      "You're welcome. I hope you find the perfect resort for your vacation.<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(dataset[\"train\"][0][\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sample = dataset[\"train\"][1]\n",
    "batch_sample = {k: v for k, v in batch_sample.items() if k in [\"input_ids\"]}\n",
    "# print([len(v) for v in batch_sample[\"input_ids\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': torch.Size([224]), 'attention_mask': torch.Size([224])}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = data_collator(batch_sample)\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "input = \"Hi, how are you feeling now?\"\n",
    "\n",
    "batch = tokenizer(input, return_tensors=\"pt\").to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[26843,    28,   638,   359,   346,  4330,  1209,    47]],\n",
       "       device='mps:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]], device='mps:0')}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"labels\"] = batch[\"input_ids\"].clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(49152, 576)\n",
       "    (layers): ModuleList(\n",
       "      (0-29): 30 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=576, out_features=576, bias=False)\n",
       "          (k_proj): Linear(in_features=576, out_features=192, bias=False)\n",
       "          (v_proj): Linear(in_features=576, out_features=192, bias=False)\n",
       "          (o_proj): Linear(in_features=576, out_features=576, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=576, out_features=1536, bias=False)\n",
       "          (up_proj): Linear(in_features=576, out_features=1536, bias=False)\n",
       "          (down_proj): Linear(in_features=1536, out_features=576, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((576,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((576,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((576,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=576, out_features=49152, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CausalLMOutputWithPast(loss=tensor(2.4997, device='mps:0', grad_fn=<NllLossBackward0>), logits=tensor([[[ 19.0812,   7.8402,   7.9945,  ...,  14.6980,  17.8165,  15.4678],\n",
       "         [  3.3337, -13.5207, -13.4428,  ...,  -5.5125,   3.0314,  -4.4235],\n",
       "         [ 13.7915,  -3.0126,  -2.8766,  ...,   6.5830,  10.6706,   5.3863],\n",
       "         ...,\n",
       "         [  7.8826,  -8.5522,  -8.5129,  ...,  -2.4695,   6.1667,  -3.0178],\n",
       "         [  3.6068, -11.8111, -11.7401,  ...,  -5.4752,   2.4249,  -6.6690],\n",
       "         [  6.6683, -11.8877, -11.8476,  ...,  -5.0822,   2.9220,  -3.3430]]],\n",
       "       device='mps:0', grad_fn=<LinearBackward0>), past_key_values=DynamicCache(), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 19.0812,   7.8402,   7.9945,  ...,  14.6980,  17.8165,  15.4678],\n",
      "        [  3.3337, -13.5207, -13.4428,  ...,  -5.5125,   3.0314,  -4.4235],\n",
      "        [ 13.7915,  -3.0126,  -2.8766,  ...,   6.5830,  10.6706,   5.3863],\n",
      "        ...,\n",
      "        [  7.8826,  -8.5522,  -8.5129,  ...,  -2.4695,   6.1667,  -3.0178],\n",
      "        [  3.6068, -11.8111, -11.7401,  ...,  -5.4752,   2.4249,  -6.6690],\n",
      "        [  6.6683, -11.8877, -11.8476,  ...,  -5.0822,   2.9220,  -3.3430]],\n",
      "       device='mps:0', grad_fn=<SelectBackward0>)\n",
      "torch.Size([8, 49152])\n"
     ]
    }
   ],
   "source": [
    "print(outputs[\"logits\"][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input                          | GroundTruth  | Prediction | Top10                              \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Hi                             | ,            | ,          | ,.!- to?:);]                       \n",
      "Hi,                            | how          | I          | I you it that Mr\\n this my how thanks\n",
      "Hi, how                        | are          | can        | can are do did about many coulddy much is\n",
      "Hi, how are                    | you          | you        | you we the your things they my these YOU ya\n",
      "Hi, how are you                | feeling      | doing      | doing? feeling?\", going today?” getting all\n",
      "Hi, how are you feeling        | now          | ?          | ? today?\",?” about this now right so\n",
      "Hi, how are you feeling now    | ?            | ?          | ??\",?”!.?' that?! and              \n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Input':30} | {'GroundTruth':12} | {'Prediction':10} | {'Top10':35}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for i, logits in enumerate(ouputs[\"logits\"][0]):\n",
    "    if i + 1 >= len(batch[\"input_ids\"][0]):\n",
    "        break\n",
    "    values, token_ids = torch.topk(logits, k=10)\n",
    "    input = (\n",
    "        tokenizer.decode(batch[\"input_ids\"][0][: i + 1]).strip().replace(\"\\n\", \"\\\\n\")\n",
    "    )\n",
    "    truth = tokenizer.decode(batch[\"input_ids\"][0][i + 1]).strip().replace(\"\\n\", \"\\\\n\")\n",
    "    pred = tokenizer.decode(token_ids[0]).strip().replace(\"\\n\", \"\\\\n\")\n",
    "    top_5 = tokenizer.decode(token_ids).strip().replace(\"\\n\", \"\\\\n\")\n",
    "\n",
    "    print(f\"{input:30} | {truth:12} | {pred:10} | {top_5:35}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# last logit is for the prediction after the last input token. \n",
    "# we don't have ground truth for it.\n",
    "\n",
    "tokenizer.decode(torch.argmax(ouputs[\"logits\"][0][-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss is a single float value, meaning it has been summed up losses across all tokens and averaged them. \n",
    "When this loss is backpropagated, the loss for each token will be applied separately though. Keep in mind that this loss value is a sum of all weights and input embedding vector's multiplications. When derivate this w.r.t certain parameter, you are going to apply that to all losses of the tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4997, device='mps:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full code for training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW, get_scheduler\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"train\"], shuffle=True, batch_size=8, collate_fn=data_collator\n",
    ")\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=3e-5)\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "\n",
    "model.train()\n",
    "for batch in train_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    outputs = model(**batch)\n",
    "\n",
    "    loss = outputs.loss\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    lr_scheduler.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
